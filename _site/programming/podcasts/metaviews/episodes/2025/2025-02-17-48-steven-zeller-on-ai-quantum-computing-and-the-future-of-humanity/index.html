<p>Jesse Hirsh, in a lively conversation with guest Steven Zeller, delves into the transformative world of AI agents, quantum computing, and genetic hacking. The dialogue kicks off with an exploration of AI's burgeoning presence in the workplace, where Zeller emphasizes the immediate implications of AI agents on various industries. He cites the launch of Grok 3, a new AI model that promises to elevate the capabilities of agentic AI. With an impressive processing power fueled by a staggering number of GPUs, Grok 3 is set to compete fiercely in the AI landscape, raising the stakes for companies like OpenAI and Deep Seq. Zeller discusses the importance of reasoning capabilities in AI, suggesting that the true measure of success for these agents lies in their ability to think critically and adapt intelligently to complex scenarios.</p>
<p>As the conversation progresses, the duo shifts gears to quantum computing, with Zeller speculating on its potential to disrupt existing technological paradigms. He highlights the escalating competition between nations, particularly between the U.S. and China, in the race for quantum supremacy. The discussion touches on the ethical dilemmas posed by these advancements, particularly in terms of privacy and data security. Zeller warns that the rapid implementation of quantum technologies could lead to unforeseen consequences, including breaches of security that could put sensitive information at risk. This aspect of the conversation underscores the urgent need for robust regulatory frameworks that can keep pace with technological advancements.</p>
<p>Finally, the episode culminates in a thought-provoking exploration of genetic hacking. Zeller presents a nuanced view on the moral implications of altering human genetics, debating the fine line between medical advancement and ethical responsibility. He argues for proactive engagement with genetic technologies, emphasizing the potential benefits of eradicating diseases and extending human longevity. However, he acknowledges the risks associated with such power, questioning who gets to decide how these technologies are used and for what purposes. This vibrant exchange invites listeners to reflect on the future of humanity in a world increasingly shaped by AI, quantum computing, and genetic engineering, urging them to consider the profound ethical implications of the choices we make today.</p>
<p>Takeaways:</p>
<ul>
<li>The rise of AI agents is not a distant future; it's transforming workplaces today, impacting how we work and interact with technology.</li>
<li>Grok 3's launch is highly anticipated as it utilizes a staggering amount of GPU power, significantly more than its competitors, potentially leading to groundbreaking capabilities.</li>
<li>The conversation around agentic AI emphasizes the importance of reasoning capabilities, essential for its effectiveness in real-world applications across various industries.</li>
<li>Humanoid robotics is becoming a multibillion dollar industry, with companies like BMW leading the charge in integrating advanced AI into their operations.</li>
<li>The ethical implications of genetic engineering raise complex questions about consent and the potential for misuse as we advance in technology.</li>
<li>Quantum computing's implications for security and data integrity are profound, necessitating robust defenses against potential cyber threats from advanced technologies.</li>
</ul>
<hr>
<h2>Transcript</h2>
<p>a:5:{s:22:&quot;transcription_uploaded&quot;;s:4:&quot;file&quot;;s:18:&quot;transcription_html&quot;;s:91:&quot;https://transcripts.captivate.fm/transcript/bebe1ec1-3b3f-4a01-bbb9-72c57213bb0e/index.html&quot;;s:18:&quot;transcription_file&quot;;s:95:&quot;https://transcripts.captivate.fm/transcript/bebe1ec1-3b3f-4a01-bbb9-72c57213bb0e/transcript.srt&quot;;s:18:&quot;transcription_json&quot;;s:96:&quot;https://transcripts.captivate.fm/transcript/bebe1ec1-3b3f-4a01-bbb9-72c57213bb0e/transcript.json&quot;;s:18:&quot;transcription_text&quot;;s:61258:&quot;Speaker A 00:00:01</p>
<p>Hi, I'm Jesse Hirsch, and welcome to another episode of Metaviews, recorded live in front of an automated audience.</p>
<p>Speaker A 00:00:15</p>
<p>And today we're going to talk about the agents among us, although more practically the rise of AI agents of robots in the workplace, amongst a range of other fascinating, almost future futuristic, but not really in that we're talking about these technologies in the present tense, in the present context.</p>
<p>Speaker A 00:00:40</p>
<p>And we've got Steven Zeller here with us as our guest today to try to help us.</p>
<p>Speaker A 00:00:46</p>
<p>And Steven, this is where I have to tell you that as a podcast, we're constantly evolving.</p>
<p>Speaker A 00:00:53</p>
<p>And while our methodology is the spontaneous conversation, we're kind of riffing off a game show vibe as we use different segments with each episode.</p>
<p>Speaker A 00:01:07</p>
<p>And we always start with the news, partly because Metaviews publishes a daily newsletter that we like to promote.</p>
<p>Speaker A 00:01:17</p>
<p>But really the purpose of our news segment, Stephen, is to throw to the guest and say, you know, what are you paying attention to?</p>
<p>Speaker A 00:01:25</p>
<p>What are you following?</p>
<p>Speaker A 00:01:26</p>
<p>This could be personal news, could be industry news, world news, technology news.</p>
<p>Speaker A 00:01:32</p>
<p>This is kind of meant as an intuitive test to really see where your mind is at, but also fundamentally answer the question, what should our audience be paying attention to right now?</p>
<p>Speaker B 00:01:47</p>
<p>This is going to take the entire segment, Jesse.</p>
<p>Speaker B 00:01:50</p>
<p>I'll narrow it down to just one, just because it's relevant to the conversation we're about to have.</p>
<p>Speaker B 00:01:56</p>
<p>And it's the announced release of Grok 3, which is supposed to be.</p>
<p>Speaker B 00:02:04</p>
<p>It's slated to be released today, which is Monday, what is this?</p>
<p>Speaker B 00:02:08</p>
<p>17th of February 2025.</p>
<p>Speaker B 00:02:12</p>
<p>So that one is going to be interesting.</p>
<p>Speaker B 00:02:14</p>
<p>So I am watching that mainly because I want to do a analysis or a side by side comparison of the other competitors, just to see how it stacks up.</p>
<p>Speaker B 00:02:24</p>
<p>Speaking of stacks, one of the key things that I'm looking for is it was trained with, or at least supposedly so.</p>
<p>Speaker B 00:02:33</p>
<p>I have not personally verified this information.</p>
<p>Speaker A 00:02:36</p>
<p>Myself, however, and in your defense, this is the news segment and you're breaking news, so well done.</p>
<p>Speaker A 00:02:42</p>
<p>Please continue.</p>
<p>Speaker B 00:02:45</p>
<p>So it was supposedly trained with, utilizing 100,000 GPUs.</p>
<p>Speaker B 00:02:50</p>
<p>Nvidia GPUs.</p>
<p>Speaker A 00:02:52</p>
<p>For context, this is the Memphis Data center, right?</p>
<p>Speaker B 00:02:55</p>
<p>Correct.</p>
<p>Speaker B 00:02:56</p>
<p>Yes.</p>
<p>Speaker B 00:02:58</p>
<p>Massive.</p>
<p>Speaker B 00:02:59</p>
<p>Imagine two to 300 rows of these servers.</p>
<p>Speaker B 00:03:05</p>
<p>It's absolutely insane the scope or scale of this thing.</p>
<p>Speaker B 00:03:10</p>
<p>But for context, from a competitive nature, Llama 3 and ChatGPT 4 were both.</p>
<p>Speaker B 00:03:18</p>
<p>They both utilized around roughly around 25,000, so about a fourth of the GPU processing power.</p>
<p>Speaker B 00:03:26</p>
<p>So one might assume, therefore, that this one is going to be a very powerful AI.</p>
<p>Speaker B 00:03:32</p>
<p>That's going to be introduced.</p>
<p>Speaker B 00:03:33</p>
<p>However, we just this about three weeks ago, two to three weeks ago, we just had OpenAI come out with their version of agentic AI, which is it's still in its relative infancy.</p>
<p>Speaker B 00:03:51</p>
<p>So there's a lot of bugs to be worked out.</p>
<p>Speaker B 00:03:52</p>
<p>But it's going to be interesting not just how Grok3 rolls out from a comparison perspective, but also what is it going to be an agentic AI similar to what OpenAI and Deep Seq have rolled out, or is it going to be more of a ChatGPT 1, 2.</p>
<p>Speaker A 00:04:11</p>
<p>And 3 and you know, just to spell out for our listeners who may not have our mutual literacy by agentic, you're talking about agents in terms of what the AI can do.</p>
<p>Speaker A 00:04:21</p>
<p>But a follow up question I have for you is the other hyped feature right now seems to be reasoning and to what extent do you think that Grok version 3 will either also feel a kind of peer pressure need to say, hey look, our machine can really reason quite deeply as well, or alternatively, is there a new feature that we haven't really seen yet that if Grok 3 exhibited it would all of a sudden get all the attention on them and sort of set them in the lead?</p>
<p>Speaker A 00:04:58</p>
<p>Especially if AGI or superior AI is meant to be the kind of destination for all these companies, it is the.</p>
<p>Speaker B 00:05:07</p>
<p>Destination that everybody is trying to achieve.</p>
<p>Speaker B 00:05:09</p>
<p>Right.</p>
<p>Speaker B 00:05:10</p>
<p>And the competition is thick.</p>
<p>Speaker B 00:05:13</p>
<p>It's how many billions can you throw at the actual processing power that's going behind this, the rollouts of each new iteration?</p>
<p>Speaker B 00:05:21</p>
<p>Right.</p>
<p>Speaker B 00:05:21</p>
<p>So to answer your question is difficult.</p>
<p>Speaker B 00:05:25</p>
<p>Right.</p>
<p>Speaker B 00:05:25</p>
<p>So as soon as they roll out, there's going to be a lot of people testing it, a lot of people doing side by side comparisons.</p>
<p>Speaker B 00:05:30</p>
<p>YouTube is going to blow up because that's just the nature of YouTube.</p>
<p>Speaker B 00:05:35</p>
<p>So I think what you're going to be looking for is the reasoning capabilities.</p>
<p>Speaker B 00:05:39</p>
<p>Right.</p>
<p>Speaker B 00:05:39</p>
<p>And the thing is, the fun thing is I'm not sure if you're familiar with Deep Sea Chinese.</p>
<p>Speaker A 00:05:46</p>
<p>Yeah, we talked about it quite a bit on the show.</p>
<p>Speaker B 00:05:49</p>
<p>Yes.</p>
<p>Speaker B 00:05:53</p>
<p>If you've already gone over it, I won't give you my two cents.</p>
<p>Speaker A 00:05:55</p>
<p>No, I do want to hear your two cents.</p>
<p>Speaker A 00:05:57</p>
<p>To your point, you don't need to give us the precis, but you can jump right down to how you think it's impacting the race, the arms race.</p>
<p>Speaker B 00:06:05</p>
<p>It's impacting it dramatically.</p>
<p>Speaker B 00:06:08</p>
<p>I mean obviously everybody in the US wants it to be a supremacy, to belong to us.</p>
<p>Speaker B 00:06:14</p>
<p>Other.</p>
<p>Speaker B 00:06:16</p>
<p>There are other people obviously throughout the world that are cheering on China.</p>
<p>Speaker B 00:06:20</p>
<p>It's kind of, I don't want to say an arms race, but it's definitely a tech race.</p>
<p>Speaker B 00:06:24</p>
<p>And the fun thing about China is you don't know what they have until they roll it out and it goes mainstream.</p>
<p>Speaker B 00:06:29</p>
<p>They're very silent.</p>
<p>Speaker B 00:06:31</p>
<p>It's an authoritarian regime.</p>
<p>Speaker B 00:06:32</p>
<p>They lock down their scientists hardcore until they're ready to release something and then it blows up.</p>
<p>Speaker B 00:06:39</p>
<p>So that barrier to visibility is our transparency rather is something that scares a lot of people, is we have no idea what they're capable of until they roll it out.</p>
<p>Speaker B 00:06:51</p>
<p>However, I mean just my take on it, your data, your key, everyone's up in arms that, oh, they're, they're monitoring our keystrokes, our search history.</p>
<p>Speaker B 00:07:01</p>
<p>Everyone is doing that.</p>
<p>Speaker B 00:07:03</p>
<p>Google's been doing that for years.</p>
<p>Speaker B 00:07:04</p>
<p>Every single time you go on the web, I mean obviously there are certain things that you can do to limit that visibility.</p>
<p>Speaker B 00:07:13</p>
<p>Right, that these tech companies do, but every single one of them does.</p>
<p>Speaker B 00:07:16</p>
<p>Does it.</p>
<p>Speaker B 00:07:16</p>
<p>Now the question is, okay, do I want to give that data to a Chinese based companies or an American based company?</p>
<p>Speaker B 00:07:24</p>
<p>Regardless, it's going somewhere.</p>
<p>Speaker A 00:07:25</p>
<p>Well, and you know, as we've seen currently, China's going to take that data whether anyone has given them permission to or not.</p>
<p>Speaker A 00:07:39</p>
<p>That is the byproduct of that data being there.</p>
<p>Speaker A 00:07:42</p>
<p>I want to transition to our next segment.</p>
<p>Speaker A 00:07:45</p>
<p>Congratulations, you passed our first segment with flying colors.</p>
<p>Speaker A 00:07:49</p>
<p>A couple of institutional memory to share with you.</p>
<p>Speaker A 00:07:52</p>
<p>We use the language arms race with AI because we recognize that AI is going to be powering all the arms.</p>
<p>Speaker A 00:07:58</p>
<p>So whoever ends up developing the AI is therefore going to have a military advantage because of the capability it will translate to, as we've seen in Ukraine, in terms of the way that military conflict has paid out.</p>
<p>Speaker A 00:08:13</p>
<p>And we've also come to a rather contradictory or radical position here at metiviews, which is the data's not that really important.</p>
<p>Speaker A 00:08:21</p>
<p>It is for training AI, but the paranoia that a lot of individuals have with regard to their own data is misplaced because it's their attention that's really valuable and it's where they allocate their attention that I think really results in political power, economic power, not so much the data.</p>
<p>Speaker A 00:08:42</p>
<p>Like the marketing industry would love us to believe that data is all powerful and data scientists love to say that data is all powerful.</p>
<p>Speaker A 00:08:50</p>
<p>And yes, you need a lot of data to train AI.</p>
<p>Speaker A 00:08:53</p>
<p>But I think attention is the real crux of the issue.</p>
<p>Speaker A 00:09:00</p>
<p>But that brings us to our second segment that we have here on every meta views, which is WTF or what's the Future.</p>
<p>Speaker A 00:09:10</p>
<p>And again, like the news segment where we want to tap into your intuition.</p>
<p>Speaker A 00:09:16</p>
<p>Right.</p>
<p>Speaker A 00:09:16</p>
<p>We want you to share with our audience what you see on the event horizon and therefore what they should be looking at.</p>
<p>Speaker A 00:09:24</p>
<p>You know, to go back to my point about attention, that nothing is inevitable, provided you are paying attention and are ready to handle any crisis as if it's actually an opportunity.</p>
<p>Speaker B 00:09:37</p>
<p>Fair enough.</p>
<p>Speaker B 00:09:39</p>
<p>So further define that, what you're saying.</p>
<p>Speaker B 00:09:43</p>
<p>So I'm going to go ahead and just get back to kind of the topic we initially started off on, because when you say, what?</p>
<p>Speaker B 00:09:51</p>
<p>Wtf?</p>
<p>Speaker B 00:09:52</p>
<p>What's the future?</p>
<p>Speaker B 00:09:53</p>
<p>Oh my gosh, the future is going to be changing dramatically on so many different fronts within the next five years.</p>
<p>Speaker B 00:10:00</p>
<p>A lot of people, a lot of listeners to your show probably don't grasp how fast it's going to change.</p>
<p>Speaker B 00:10:05</p>
<p>But one thing that you're going to see that I think is relevant to our initial topic for this conversation is the imminent implementation and adoption of agentic AI, which we can further define here momentarily into the workforce.</p>
<p>Speaker B 00:10:24</p>
<p>And we're talking not just from a virtual perspective, but we're also talking humanoid robotics.</p>
<p>Speaker B 00:10:29</p>
<p>Humanoid robotics is a multibillion dollar industry that obviously everyone knows which companies are leading the way.</p>
<p>Speaker B 00:10:36</p>
<p>There's a lot of different people throwing their hats in there, but there are only a few key players that are going to be able to roll these out in bulk.</p>
<p>Speaker B 00:10:44</p>
<p>And they're going to have massive sway in the corporations that are those contracts just kind of, just kind of like how Nvidia kind of monopolized the industry.</p>
<p>Speaker B 00:10:58</p>
<p>The robotics is going to be relatively similar now.</p>
<p>Speaker B 00:11:00</p>
<p>There are going to be different robotics companies that have their niche.</p>
<p>Speaker B 00:11:04</p>
<p>Right.</p>
<p>Speaker B 00:11:04</p>
<p>So they're good at maybe medical device or surgical operations that are operated autonomously.</p>
<p>Speaker B 00:11:12</p>
<p>Right.</p>
<p>Speaker B 00:11:12</p>
<p>That's, that's something that's happening.</p>
<p>Speaker B 00:11:14</p>
<p>So you might have one company that leads that sector.</p>
<p>Speaker B 00:11:16</p>
<p>But overall, when you talk about humanoid robotics with integrated agentic reasoning capabilities, that is something that is not just on the horizon 10 years.</p>
<p>Speaker B 00:11:27</p>
<p>That is something that is happening right now and it's happening in a big way.</p>
<p>Speaker B 00:11:30</p>
<p>We already see companies like BMW implementing it and Amazon is implementing it.</p>
<p>Speaker B 00:11:37</p>
<p>There's all these different companies.</p>
<p>Speaker B 00:11:38</p>
<p>And let's not even start about China.</p>
<p>Speaker B 00:11:40</p>
<p>You're going to start seeing a lot first.</p>
<p>Speaker B 00:11:44</p>
<p>You're going to see virtual, the agentic AIs that's going to start being implemented into one of these companies.</p>
<p>Speaker A 00:11:50</p>
<p>And let me first, Congratulations, you passed the future segment.</p>
<p>Speaker A 00:11:55</p>
<p>We're into the feature conversation, which we'll start by talking about agents.</p>
<p>Speaker A 00:12:01</p>
<p>Can you be more Specific.</p>
<p>Speaker A 00:12:02</p>
<p>And by more specific I mean I agree with you in terms of the niches and the specialization, but arbitrarily for our listeners, Pick an industry, any industry, and then spell out how you see agents playing a role.</p>
<p>Speaker A 00:12:20</p>
<p>And you're more than welcome to do it incrementally because to your point, it'll probably start with software.</p>
<p>Speaker A 00:12:26</p>
<p>But let's be as specific as possible so that we can make the example as tangible for people who this is new to, who this technology is still kind of more in the realm of fiction and Hollywood versus you're describ, really an industrial transformation that has tremendous implications across the board.</p>
<p>Speaker A 00:12:48</p>
<p>Again, you decide, pick an industry arbitrarily and get as much detail as you can as to, again, hypothetically how you see this playing out.</p>
<p>Speaker B 00:13:00</p>
<p>Pick an industry.</p>
<p>Speaker B 00:13:01</p>
<p>Oh boy.</p>
<p>Speaker B 00:13:03</p>
<p>I think the ones that are going to be a little bit more futuristic on the horizon are going to be the ones that require a lot of regulatory restrictions to go through and like FDA approval, things like that.</p>
<p>Speaker B 00:13:16</p>
<p>So I think one of the big ones that's going to be turned on its head is going to be surgical procedures.</p>
<p>Speaker B 00:13:22</p>
<p>I think the precision, the autonomous capabilities of robotics in surgical procedures is going to dramatically change that landscape.</p>
<p>Speaker B 00:13:29</p>
<p>That said, that is going to have to go through a lot of hurdles to get approval and go mainstream.</p>
<p>Speaker B 00:13:36</p>
<p>So I think the one that I'm going to pick that is going to have the, maybe one of the fastest implementations would be the manufacturing and logistics.</p>
<p>Speaker B 00:13:49</p>
<p>Manufacturing and logistics and some of the economic ramifications we can get into that if we have time for the segment.</p>
<p>Speaker A 00:13:54</p>
<p>But, but like you mentioned, BMW, for example.</p>
<p>Speaker A 00:13:58</p>
<p>Do you want to riff off that?</p>
<p>Speaker B 00:14:01</p>
<p>Sure.</p>
<p>Speaker B 00:14:02</p>
<p>So think of it from the company's perspective.</p>
<p>Speaker B 00:14:04</p>
<p>Right.</p>
<p>Speaker B 00:14:05</p>
<p>So you've got, you've got companies, which.</p>
<p>Speaker B 00:14:08</p>
<p>I'm not saying this is good or bad.</p>
<p>Speaker B 00:14:10</p>
<p>Right.</p>
<p>Speaker B 00:14:11</p>
<p>I'm going to stay agnostic.</p>
<p>Speaker B 00:14:12</p>
<p>I'm just saying I'm not giving you my perspective.</p>
<p>Speaker B 00:14:14</p>
<p>I'm giving you this is a reality.</p>
<p>Speaker B 00:14:16</p>
<p>This is what's going to happen regardless of your stance on it.</p>
<p>Speaker A 00:14:20</p>
<p>In your defense, you're giving an analysis.</p>
<p>Speaker A 00:14:22</p>
<p>You're not, you're not placing any moral assessment on it.</p>
<p>Speaker B 00:14:26</p>
<p>Yes.</p>
<p>Speaker B 00:14:27</p>
<p>Please do not attack me when I.</p>
<p>Speaker B 00:14:29</p>
<p>Yeah, correct, correct.</p>
<p>Speaker A 00:14:30</p>
<p>You were trying to give an analysis and in that regard, you're not placing any morality on it.</p>
<p>Speaker A 00:14:35</p>
<p>But I will point out that the analysis still reflects your cognitive biases, even if you are not suggesting whether this is good or bad as of yet.</p>
<p>Speaker A 00:14:44</p>
<p>Please continue.</p>
<p>Speaker B 00:14:46</p>
<p>Fair enough and thank you for pointing that out.</p>
<p>Speaker B 00:14:51</p>
<p>Now, cognitive biases aside, one Thing that we're going to see is these pilot programs are going to definitely be utilized to optimize the systems.</p>
<p>Speaker B 00:15:01</p>
<p>And once that happens, which is primarily a software issue, right, they got to get all the bugs out.</p>
<p>Speaker B 00:15:05</p>
<p>They got to make sure that the automation that they are programming into these humanoid robots and the reasoning capabilities are actually working and they are scalable.</p>
<p>Speaker B 00:15:13</p>
<p>Once that threshold is crossed, which I think will happen within a year, it's going to roll out very quickly.</p>
<p>Speaker B 00:15:19</p>
<p>And when you start thinking about it from the perspective of the manufacturers, you start thinking, okay, so if I can acquire, what is my cost?</p>
<p>Speaker B 00:15:28</p>
<p>Their goal is profitability, like every company.</p>
<p>Speaker B 00:15:31</p>
<p>So if their cost per human on that line is, let's say, $46,000, $50,000 per year, plus HR and benefits, and you can implement a humanoid robot that doesn't sleep, right?</p>
<p>Speaker B 00:15:47</p>
<p>So start thinking about that.</p>
<p>Speaker B 00:15:48</p>
<p>247 operations from a single humanoid robot that costs them 25 to $30,000 one time with obviously some, some recurring maintenance that needs to happen quarterly or annually, whatever that may be.</p>
<p>Speaker B 00:16:03</p>
<p>From a business owner perspective, right, you're thinking about your bottom line.</p>
<p>Speaker B 00:16:06</p>
<p>You're thinking about profitability, you're thinking about the future of the company.</p>
<p>Speaker B 00:16:09</p>
<p>What do you think is going to happen?</p>
<p>Speaker B 00:16:11</p>
<p>You're going to start seeing, I'm going to put an order in.</p>
<p>Speaker B 00:16:15</p>
<p>We've already worked out the bugs.</p>
<p>Speaker B 00:16:16</p>
<p>Here's the efficiencies, here's the downfalls, the risk.</p>
<p>Speaker B 00:16:20</p>
<p>I'm not going to go full autonomy.</p>
<p>Speaker B 00:16:21</p>
<p>We're still going to require some human workers.</p>
<p>Speaker B 00:16:23</p>
<p>But I can replace 20%, 30% of my workers, and that's going to increase my bottom line by X.</p>
<p>Speaker B 00:16:29</p>
<p>Especially when you start looking at LTV long term.</p>
<p>Speaker A 00:16:31</p>
<p>Well, and one assumes you're also upgrading the capabilities in terms of you're not just replicating the labor, you're starting by replicating the labor, but then you're adding machines fundamentally can do things that humans cannot.</p>
<p>Speaker A 00:16:46</p>
<p>But since I started our conversation by suggesting that we are increasingly becoming a game show, allow me to throw you a radical curveball as a form of changing subjects, but to really put your mind in a pivot that I suspect you will enjoy.</p>
<p>Speaker A 00:17:05</p>
<p>So the scenario which we both sort of agree on, a factory owner company starts adopting these humanoid robots which change, upgrade the whole capacity and capability of manufacturing as a whole.</p>
<p>Speaker A 00:17:21</p>
<p>But then little do we know that China has a breakthrough in quantum computing and all of a sudden is able to break into the security that operates these robots and sabotages the plant covertly as part of a larger industrial crisis.</p>
<p>Speaker A 00:17:42</p>
<p>Again, Forget the factory.</p>
<p>Speaker A 00:17:45</p>
<p>That guy's problem is gone.</p>
<p>Speaker A 00:17:47</p>
<p>Let's talk about quantum computing and the potential disruption.</p>
<p>Speaker A 00:17:52</p>
<p>And I loved how when we talked about agents, you were very generous with timelines.</p>
<p>Speaker A 00:17:57</p>
<p>And by generous, I mean many people don't want to say timelines.</p>
<p>Speaker A 00:18:00</p>
<p>Right.</p>
<p>Speaker A 00:18:01</p>
<p>They don't want to take the risk of being wrong.</p>
<p>Speaker A 00:18:02</p>
<p>So I appreciate that.</p>
<p>Speaker A 00:18:04</p>
<p>I'd love if you would similarly speculate on timelines with regard to the rise of quantum computing.</p>
<p>Speaker A 00:18:10</p>
<p>But let's start with the impact, especially if you'll indulge me in this China scenario that you kind of set up.</p>
<p>Speaker A 00:18:18</p>
<p>Right to the point that I did.</p>
<p>Speaker B 00:18:20</p>
<p>Give you a softball on that one.</p>
<p>Speaker A 00:18:21</p>
<p>Yeah.</p>
<p>Speaker A 00:18:21</p>
<p>Well, but to your point, they could surprise the world due to the nature of their significant engineering and innovative capacity.</p>
<p>Speaker A 00:18:31</p>
<p>That can be done under stealth mode.</p>
<p>Speaker A 00:18:33</p>
<p>And then bamboo, you know, kind of disrupt the market without anyone really knowing.</p>
<p>Speaker A 00:18:40</p>
<p>If that were to be quantum, what would you see happening?</p>
<p>Speaker B 00:18:44</p>
<p>So we're already assuming that that is going to happen.</p>
<p>Speaker B 00:18:47</p>
<p>You have to.</p>
<p>Speaker B 00:18:48</p>
<p>I mean, from a government and industrial perspective, you got to automatically assume that that's happening.</p>
<p>Speaker B 00:18:53</p>
<p>But we've been assuming hacks have not.</p>
<p>Speaker B 00:18:56</p>
<p>Are not new to us.</p>
<p>Speaker B 00:18:57</p>
<p>Every company, Amazon.</p>
<p>Speaker A 00:19:02</p>
<p>I got to push back, though.</p>
<p>Speaker A 00:19:03</p>
<p>Hold on.</p>
<p>Speaker A 00:19:04</p>
<p>I acknowledge your we, but you have to acknowledge there's not a lot of people in that we like.</p>
<p>Speaker A 00:19:12</p>
<p>Correct you, Steven.</p>
<p>Speaker A 00:19:13</p>
<p>You would anticipate that.</p>
<p>Speaker A 00:19:15</p>
<p>More power to you.</p>
<p>Speaker A 00:19:16</p>
<p>And yes, there are some corporations who would anticipate that, but you must acknowledge that.</p>
<p>Speaker A 00:19:23</p>
<p>That we is not as inclusive as you might wish it to be.</p>
<p>Speaker B 00:19:29</p>
<p>You would be surprised, Jesse, at every.</p>
<p>Speaker B 00:19:32</p>
<p>The amount.</p>
<p>Speaker B 00:19:33</p>
<p>Every single major company that has a cto, their biggest task is don't get hacked.</p>
<p>Speaker B 00:19:39</p>
<p>And they're given a big budget, but.</p>
<p>Speaker A 00:19:40</p>
<p>They'Re not successful at that.</p>
<p>Speaker A 00:19:42</p>
<p>We hear these hacks all the time, Steven.</p>
<p>Speaker A 00:19:45</p>
<p>I agree with you.</p>
<p>Speaker A 00:19:46</p>
<p>That's their job.</p>
<p>Speaker A 00:19:47</p>
<p>But their competency varies tremendously.</p>
<p>Speaker B 00:19:50</p>
<p>Of course.</p>
<p>Speaker B 00:19:51</p>
<p>Of course.</p>
<p>Speaker B 00:19:52</p>
<p>But what I would say, and I've actually been looking at, I'm very interested, and I would say there are many people that know a little bit more about this space than I do.</p>
<p>Speaker B 00:20:01</p>
<p>But I'm very educated on the quantum sector.</p>
<p>Speaker B 00:20:06</p>
<p>There's companies that are already working with the dod, Department of Defense.</p>
<p>Speaker B 00:20:11</p>
<p>So it's primarily working with quantum resiliency.</p>
<p>Speaker B 00:20:15</p>
<p>So basically, you have to say, okay, so if and when.</p>
<p>Speaker B 00:20:18</p>
<p>Right.</p>
<p>Speaker B 00:20:18</p>
<p>So the win I can't give you.</p>
<p>Speaker B 00:20:21</p>
<p>But I do believe it is you can't even.</p>
<p>Speaker A 00:20:24</p>
<p>You can't even spitball it.</p>
<p>Speaker B 00:20:25</p>
<p>You can't even spitball it because again, you don't know China's potential and capability.</p>
<p>Speaker B 00:20:30</p>
<p>Right now we have so many issues.</p>
<p>Speaker B 00:20:33</p>
<p>I've looked at so many different product projects and there's also different ways of doing it.</p>
<p>Speaker B 00:20:38</p>
<p>Right.</p>
<p>Speaker B 00:20:39</p>
<p>So are you going with the dots?</p>
<p>Speaker B 00:20:40</p>
<p>Are you going with light?</p>
<p>Speaker B 00:20:42</p>
<p>Like, how are you actually getting to this quantum state?</p>
<p>Speaker B 00:20:44</p>
<p>Are you going with superconducting?</p>
<p>Speaker B 00:20:46</p>
<p>So there's multiple methods that are being tested.</p>
<p>Speaker B 00:20:50</p>
<p>Every single one of them has scalability problems.</p>
<p>Speaker B 00:20:52</p>
<p>When someone comes out and says, we have achieved quantum supremacy, if you actually look at the capabilities of that technology is so negligible, you would laugh.</p>
<p>Speaker B 00:21:03</p>
<p>So I think we're very.</p>
<p>Speaker B 00:21:05</p>
<p>Granted, I have no idea what China has access to.</p>
<p>Speaker B 00:21:08</p>
<p>And you are correct in saying that they could surprise us.</p>
<p>Speaker B 00:21:11</p>
<p>But even if they were to surprise us, because we're already building in quantum resiliency into a lot of our systems, especially from a military perspective, with the DoD now, industry is lagging behind.</p>
<p>Speaker A 00:21:25</p>
<p>Of course, that's what I was gonna say.</p>
<p>Speaker A 00:21:26</p>
<p>Like, I will grant you the we.</p>
<p>Speaker A 00:21:28</p>
<p>If you were Talking about the DoD.</p>
<p>Speaker B 00:21:29</p>
<p>I will grant you.</p>
<p>Speaker A 00:21:31</p>
<p>And if you were talking about, like the ic, the intelligence community, again, I would grant you that we.</p>
<p>Speaker A 00:21:37</p>
<p>But even the rest of the government outside of that, I don't know if that we is there entirely.</p>
<p>Speaker A 00:21:43</p>
<p>And in the corporate world, it's mixed.</p>
<p>Speaker A 00:21:45</p>
<p>There are some who are totally into this, zeroed in, and there are others who are like, question computing.</p>
<p>Speaker A 00:21:51</p>
<p>What are you talking about?</p>
<p>Speaker A 00:21:54</p>
<p>This is the diverse nature of knowledge in the society we live in.</p>
<p>Speaker A 00:22:00</p>
<p>But on a commercial level, because we've been talking about quantum, really where it matters, I think, which is around security and encryption.</p>
<p>Speaker A 00:22:09</p>
<p>But of course it applies elsewhere.</p>
<p>Speaker A 00:22:12</p>
<p>And I'm curious, and you can choose, because I do want to get to genetics.</p>
<p>Speaker A 00:22:16</p>
<p>You can choose whether you want to answer this on the research level or whether you want to answer this on, like, the product or application level.</p>
<p>Speaker A 00:22:23</p>
<p>But outside of kind of military and government applications, where.</p>
<p>Speaker A 00:22:27</p>
<p>Where do you see quantum really making a difference?</p>
<p>Speaker A 00:22:29</p>
<p>Like, what are, you know, the industries or the areas that quantum is going to have, you know, such a tremendous either positive or negative impact, primarily physics.</p>
<p>Speaker B 00:22:40</p>
<p>Physics, breakthrough, medic, medical applications is going to be probably the biggest, just because it takes, I mean, the complexity of the human body, which is a great segue into the next sector of this conversation.</p>
<p>Speaker B 00:22:52</p>
<p>I think that is some of the biggest ramifications that it's going to have.</p>
<p>Speaker B 00:22:55</p>
<p>Astronomy, the ability to analyze the trillions and trillions of stars out there for all the various components and molecular things that are out there.</p>
<p>Speaker B 00:23:07</p>
<p>Dark matter, right.</p>
<p>Speaker B 00:23:08</p>
<p>Is it real?</p>
<p>Speaker B 00:23:09</p>
<p>Is it fake?</p>
<p>Speaker B 00:23:09</p>
<p>There's a Lot of different things that require a significant amount of computing power that we just don't have currently.</p>
<p>Speaker B 00:23:15</p>
<p>So I think those are the biggest applications outside of secure security.</p>
<p>Speaker B 00:23:18</p>
<p>But security is probably the one that's the most detrimental to humanity.</p>
<p>Speaker B 00:23:23</p>
<p>I think that's the one that we really need to focus on.</p>
<p>Speaker B 00:23:26</p>
<p>And it is being focused on by government agencies, which has to happen, right?</p>
<p>Speaker B 00:23:30</p>
<p>They're aware of it.</p>
<p>Speaker B 00:23:31</p>
<p>They know what's happening more than I do.</p>
<p>Speaker B 00:23:34</p>
<p>Of course.</p>
<p>Speaker B 00:23:35</p>
<p>And now you are correct.</p>
<p>Speaker B 00:23:36</p>
<p>The commercial side is lagging behind.</p>
<p>Speaker B 00:23:39</p>
<p>So that adoption, I think it will happen very quickly.</p>
<p>Speaker B 00:23:41</p>
<p>And those companies that are building in quantum resilient technologies, those are going to get very wealthy very fast.</p>
<p>Speaker B 00:23:47</p>
<p>The second a quantum computer hacks into.</p>
<p>Speaker A 00:23:51</p>
<p>An American company, It may take 1, 2 or 3.</p>
<p>Speaker A 00:23:55</p>
<p>But yes, someone usually has to get burned.</p>
<p>Speaker B 00:23:57</p>
<p>It takes two or three.</p>
<p>Speaker B 00:23:59</p>
<p>The CTO of that company needs to be fired.</p>
<p>Speaker A 00:24:02</p>
<p>Oh, no.</p>
<p>Speaker A 00:24:02</p>
<p>There will be a lot of heads that roll, without a doubt.</p>
<p>Speaker A 00:24:05</p>
<p>Like, I think we make a mistake in assuming competence in the corporate sector.</p>
<p>Speaker A 00:24:11</p>
<p>Far more so in the public sector.</p>
<p>Speaker A 00:24:12</p>
<p>I think the public sector does have a higher level of competence than people assume, but I think the corporate sector has a lower level of competence than people assume.</p>
<p>Speaker A 00:24:23</p>
<p>Again, I indulge in sweeping generalizations.</p>
<p>Speaker A 00:24:26</p>
<p>That's why I would have a podcast.</p>
<p>Speaker A 00:24:28</p>
<p>But let's talk about genetics, because that is another.</p>
<p>Speaker A 00:24:32</p>
<p>I think the through line of our conversation today is exponential change and the extent to which these technologies have a tremendous potential to change society as we know it.</p>
<p>Speaker A 00:24:45</p>
<p>Right?</p>
<p>Speaker A 00:24:45</p>
<p>To make the future so much radically different than the past.</p>
<p>Speaker A 00:24:50</p>
<p>And to your point about the complexity of the human body, it strikes me genetics far more so than the others.</p>
<p>Speaker A 00:24:58</p>
<p>Don't get me wrong, agents, I think can have a huge impact on our economy and our society, either negative or positive.</p>
<p>Speaker A 00:25:05</p>
<p>Same with quantum computing.</p>
<p>Speaker A 00:25:07</p>
<p>But I think the human body is something that we really only still scratching the surface of.</p>
<p>Speaker A 00:25:14</p>
<p>So why don't we start by kind of asking a question we haven't really asked yet, which is, what about genetics interested you?</p>
<p>Speaker A 00:25:24</p>
<p>Like, you're clearly a very intelligent person and there's any subject.</p>
<p>Speaker B 00:25:30</p>
<p>I think some might dispute that.</p>
<p>Speaker A 00:25:32</p>
<p>Well, we don't have them on a guest on the show today, so they can post it in the comments below, but I'm sure they will.</p>
<p>Speaker A 00:25:41</p>
<p>What is it about genetics that attracts you, that wants you to learn more?</p>
<p>Speaker B 00:25:48</p>
<p>What doesn't interest you about learning how your own biological systems work?</p>
<p>Speaker A 00:25:55</p>
<p>I could answer that question.</p>
<p>Speaker A 00:25:57</p>
<p>So be careful about your rhetorical tricks, but.</p>
<p>Speaker A 00:26:00</p>
<p>No, no, no, please continue.</p>
<p>Speaker A 00:26:02</p>
<p>Well, ignorance is bliss.</p>
<p>Speaker A 00:26:03</p>
<p>I don't want to know when I'm going to die.</p>
<p>Speaker A 00:26:05</p>
<p>I don't want to know what I get against sick.</p>
<p>Speaker A 00:26:07</p>
<p>I just want to go every day having a good life, living bliss, free.</p>
<p>Speaker A 00:26:11</p>
<p>As long as you tell me that the health, though, if I told, If.</p>
<p>Speaker B 00:26:15</p>
<p>I told you, if I took a look at your genetics and said that you.</p>
<p>Speaker B 00:26:18</p>
<p>There's a high potential that you could die within one month, and I can change that course, add on another 10.</p>
<p>Speaker B 00:26:25</p>
<p>Now do you care?</p>
<p>Speaker A 00:26:26</p>
<p>No, because I probably wouldn't want to change it, right?</p>
<p>Speaker A 00:26:30</p>
<p>Like, this is the power of death.</p>
<p>Speaker A 00:26:31</p>
<p>And if you told me I was dying in a month, fuck, what a month that would be.</p>
<p>Speaker A 00:26:35</p>
<p>What a bender.</p>
<p>Speaker A 00:26:37</p>
<p>And I don't know if I would die at the end of that month.</p>
<p>Speaker A 00:26:39</p>
<p>But, but, but again, this is why, personally, I love, I love genetics because it gets right into philosophy and ethics.</p>
<p>Speaker A 00:26:48</p>
<p>I interrupted you.</p>
<p>Speaker A 00:26:49</p>
<p>Please continue.</p>
<p>Speaker B 00:26:50</p>
<p>No, no, no.</p>
<p>Speaker B 00:26:50</p>
<p>And I love the conversation, right?</p>
<p>Speaker B 00:26:52</p>
<p>So there's a.</p>
<p>Speaker B 00:26:53</p>
<p>There's a huge plethora of individuals on each side of this equation, right?</p>
<p>Speaker B 00:27:00</p>
<p>A lot of people saying, no, we shouldn't play God, no, we shouldn't mess with genetics.</p>
<p>Speaker B 00:27:05</p>
<p>No, we shouldn't do this.</p>
<p>Speaker B 00:27:06</p>
<p>I'm on the pro side.</p>
<p>Speaker B 00:27:07</p>
<p>I'm very much on the pro side.</p>
<p>Speaker B 00:27:08</p>
<p>And I love having the conversation, right?</p>
<p>Speaker B 00:27:11</p>
<p>It's a fun debate that nobody really has the right answer to.</p>
<p>Speaker B 00:27:14</p>
<p>Like, if we can do this, first, what's the feasibility of human longevity of genetic engineering?</p>
<p>Speaker B 00:27:21</p>
<p>And then after we have the feasibility discussion, what's the ethical discussion about it?</p>
<p>Speaker B 00:27:26</p>
<p>So just because we can, should we.</p>
<p>Speaker B 00:27:28</p>
<p>What's the Jurassic park quote?</p>
<p>Speaker B 00:27:31</p>
<p>We spent so much time thinking about, can we do this?</p>
<p>Speaker B 00:27:35</p>
<p>Nobody ever stopped to think about should we?</p>
<p>Speaker B 00:27:38</p>
<p>Love that quote.</p>
<p>Speaker B 00:27:40</p>
<p>That said, my argument, and I'd love to get your actual response to this because it varies every single time I ask it.</p>
<p>Speaker B 00:27:49</p>
<p>Throughout history, we've gotten better and better at medicine, at helping people survive longer.</p>
<p>Speaker B 00:27:53</p>
<p>People, babies used to die significantly more than the survival rate of infants.</p>
<p>Speaker B 00:27:59</p>
<p>Now, is that or is that not a good thing?</p>
<p>Speaker B 00:28:02</p>
<p>And what do you attribute that to?</p>
<p>Speaker B 00:28:03</p>
<p>You attribute it to medical advancements.</p>
<p>Speaker B 00:28:06</p>
<p>So some, some people will argue that this is taking medicine too far.</p>
<p>Speaker B 00:28:11</p>
<p>My argument is saving lives is typically viewed as a moral obligation, as a moral and ethical good thing.</p>
<p>Speaker B 00:28:19</p>
<p>Therefore, who's to say that if I can genetically take a look and say, okay, how many people die of colon cancer every single year, I can cut that in half or eradicate it completely through genetic engineering?</p>
<p>Speaker B 00:28:34</p>
<p>Is that or is that not something that you have the obligation ethically and morally to do now?</p>
<p>Speaker B 00:28:41</p>
<p>Before you give me your answer, I'm going to acknowledge technology, no matter what it is, is and will always be misused.</p>
<p>Speaker B 00:28:51</p>
<p>Right?</p>
<p>Speaker B 00:28:52</p>
<p>Therefore, some people would raise the alarm bells and say, well, what happens when China uses this technology to build super soldiers?</p>
<p>Speaker A 00:28:59</p>
<p>Although we've been picking on China too long, today, for arbitrary sakes, let's pick on France.</p>
<p>Speaker A 00:29:05</p>
<p>Go ahead.</p>
<p>Speaker B 00:29:06</p>
<p>There we go.</p>
<p>Speaker B 00:29:07</p>
<p>What happens when France decides to build super soldiers with it?</p>
<p>Speaker B 00:29:12</p>
<p>What happens when they start cloning?</p>
<p>Speaker B 00:29:13</p>
<p>What happens with.</p>
<p>Speaker B 00:29:14</p>
<p>You can go down the rabbit hole all day long, Right?</p>
<p>Speaker B 00:29:19</p>
<p>My argument still says, just because you know that bad actors are inevitably going to misutilize this technology, is that a reason to not develop it for good?</p>
<p>Speaker A 00:29:32</p>
<p>So, a bunch of quick responses.</p>
<p>Speaker A 00:29:35</p>
<p>Number one, I'm a farmer, so I recognize that genetics is something farmers have been doing for centuries.</p>
<p>Speaker A 00:29:42</p>
<p>And, and, and that's where I kind of have a different approach to genetics than a lot of people, in that breeding is gen, and we are just now taking that to a more molecular level, to a more finite level.</p>
<p>Speaker A 00:29:55</p>
<p>So that's where, as a methodology, I don't have any problems with it.</p>
<p>Speaker A 00:29:59</p>
<p>But to your question, to me, it really comes down to the political society upon which the technology exists.</p>
<p>Speaker A 00:30:07</p>
<p>And in that sense, if we lived in a utopia where consent was the guiding principle.</p>
<p>Speaker A 00:30:13</p>
<p>Yeah, for sure, hack away.</p>
<p>Speaker A 00:30:16</p>
<p>But what worries me, and I wrote an essay on this fuck five, maybe ten years ago on Tumblr.</p>
<p>Speaker A 00:30:22</p>
<p>I think of all places called the Ethics of Immortality, which kind of argued that my fear is that this would be used to ensure that all prison sentences were served.</p>
<p>Speaker A 00:30:36</p>
<p>Like, what if you got sentenced to 200 years and they didn't fucking let you die and they kept you alive all that time just to serve out your goddamn sentence.</p>
<p>Speaker A 00:30:47</p>
<p>So, you know, like, I, on the one hand, appreciate the value of medicine and that there's a lot of people who would like to have their loved ones and they want to defeat cancer.</p>
<p>Speaker A 00:30:56</p>
<p>And I agree, on a collective level, that is a project worth pursuing.</p>
<p>Speaker A 00:31:00</p>
<p>That's some good research.</p>
<p>Speaker A 00:31:01</p>
<p>But let's also maintain people's consent to say, peace out.</p>
<p>Speaker A 00:31:05</p>
<p>I'm gone.</p>
<p>Speaker B 00:31:07</p>
<p>Freedom of choice is.</p>
<p>Speaker B 00:31:09</p>
<p>It has to be.</p>
<p>Speaker A 00:31:09</p>
<p>But it's more than freedom of choice, right?</p>
<p>Speaker A 00:31:12</p>
<p>We're choosing to take one's life and shout out to my buddy Mike Oppenheim and his podcast Coffin Talk.</p>
<p>Speaker A 00:31:19</p>
<p>These are policy issues that we just don't really talk about in our society, and we should, as the technology of genetics continues.</p>
<p>Speaker A 00:31:26</p>
<p>So I very much appreciate your thoughts and your question that you recognize that your interest in the technology Comes with a commitment to have ethical conversations and philosophical conversations.</p>
<p>Speaker A 00:31:39</p>
<p>So to that I say, right on.</p>
<p>Speaker A 00:31:41</p>
<p>But on a couple more questions, on the point of genetics, you know, just like with agents and quantum, there's a regulatory side of this that is kind of a prerequisite.</p>
<p>Speaker A 00:31:52</p>
<p>Right.</p>
<p>Speaker A 00:31:52</p>
<p>Like, you know, on the same side that you need a fertile research environment for this stuff to take place.</p>
<p>Speaker A 00:31:59</p>
<p>That's why universities have been a major player.</p>
<p>Speaker A 00:32:02</p>
<p>But moving forward, what kind of policy do you think is necessary both on the trust level so that there can be either a trust framework around this stuff, or more importantly, around an open research level that allows this technology to be researched in a way that kept it accessible.</p>
<p>Speaker A 00:32:26</p>
<p>Because, for example, what I see with, say, stem cells is stem cell therapy.</p>
<p>Speaker A 00:32:32</p>
<p>And the medicine around stem cells is quite phenomenal, but it's also very elite.</p>
<p>Speaker A 00:32:39</p>
<p>Not everyone gets access to it.</p>
<p>Speaker A 00:32:41</p>
<p>That's a policy.</p>
<p>Speaker A 00:32:42</p>
<p>That's an equity issue.</p>
<p>Speaker A 00:32:45</p>
<p>So this is me saying, as someone who wants to see this technology evolve, who from a research level is really fascinated by the positive potential of it, what are some of the policy or regulations that you think are important that we as mediviews, we like to say we reach decision makers.</p>
<p>Speaker A 00:33:07</p>
<p>What are the kinds of things that these decision makers should be thinking about?</p>
<p>Speaker A 00:33:10</p>
<p>When it comes to positive genetic policy.</p>
<p>Speaker B 00:33:14</p>
<p>Universal policy is problematic.</p>
<p>Speaker B 00:33:16</p>
<p>And you see that across every sector.</p>
<p>Speaker B 00:33:21</p>
<p>You have to start thinking about, okay, so what are the potential downfalls of over regulation?</p>
<p>Speaker B 00:33:26</p>
<p>Right, so if we overregulate, then we fall behind.</p>
<p>Speaker B 00:33:31</p>
<p>And China, who?</p>
<p>Speaker A 00:33:34</p>
<p>No, no, France.</p>
<p>Speaker A 00:33:35</p>
<p>France.</p>
<p>Speaker B 00:33:36</p>
<p>France.</p>
<p>Speaker B 00:33:37</p>
<p>We picked on France too much.</p>
<p>Speaker B 00:33:38</p>
<p>Now England, England takes over.</p>
<p>Speaker A 00:33:40</p>
<p>Okay, fair enough.</p>
<p>Speaker A 00:33:42</p>
<p>Less believable, but please continue.</p>
<p>Speaker B 00:33:45</p>
<p>You didn't say believable, you just said diversify.</p>
<p>Speaker B 00:33:51</p>
<p>So creating universal policy is problematic for the sole point of who's going to get there first?</p>
<p>Speaker B 00:33:59</p>
<p>Right.</p>
<p>Speaker B 00:33:59</p>
<p>Who's going to develop the technology and how is it going to be utilized?</p>
<p>Speaker B 00:34:02</p>
<p>Which was your point earlier, is what type of society actually is going to have access to this?</p>
<p>Speaker B 00:34:07</p>
<p>When you start talking about successability, every technology that's developed starts out expensive.</p>
<p>Speaker B 00:34:15</p>
<p>It's going to be accessible to everybody.</p>
<p>Speaker B 00:34:17</p>
<p>But there is a process.</p>
<p>Speaker B 00:34:19</p>
<p>It's expensive to develop this.</p>
<p>Speaker B 00:34:21</p>
<p>When cars first were invented, do you think it was equitable?</p>
<p>Speaker A 00:34:25</p>
<p>I gotta push back.</p>
<p>Speaker A 00:34:27</p>
<p>And I like your argument, but it's the absolutism that I have trouble with.</p>
<p>Speaker A 00:34:32</p>
<p>Okay, if you said most technology, I would agree with you, but the web hypertext transfer protocol works on port 80, works on port 443, was pretty cheap to develop, pretty cheap to deploy, and it's Changed the fucking world.</p>
<p>Speaker A 00:34:49</p>
<p>So I agree with you.</p>
<p>Speaker A 00:34:50</p>
<p>Most technologies fit the model that you were describing, but not all.</p>
<p>Speaker A 00:34:56</p>
<p>And perhaps that's another conversation for another day as to how that can happen because medical technology has a similar history of cheap shit that was easy to discover, that had a tremendous impact on people's positive of well being.</p>
<p>Speaker A 00:35:10</p>
<p>But please continue.</p>
<p>Speaker A 00:35:12</p>
<p>You were on that.</p>
<p>Speaker B 00:35:13</p>
<p>No, that's actually a fair point and you are correct.</p>
<p>Speaker B 00:35:16</p>
<p>So I should have further defined the technology that requires a tremendous exorbitant amount of capital to develop in the R and D phase.</p>
<p>Speaker B 00:35:25</p>
<p>Those it was not cheap by any means for Ford to build the car.</p>
<p>Speaker B 00:35:31</p>
<p>It was not cheap to build airplanes.</p>
<p>Speaker B 00:35:32</p>
<p>When airplanes rolled out, you couldn't get an airplane seat if you were blue collar.</p>
<p>Speaker A 00:35:36</p>
<p>Okay, but you're losing me with the choices.</p>
<p>Speaker A 00:35:41</p>
<p>And for the record, throughout our conversation today, I'm still designing the game show here that I'm trying to build.</p>
<p>Speaker A 00:35:48</p>
<p>And I think like all video games, the further you get in the game, the harder the challenge becomes.</p>
<p>Speaker A 00:35:54</p>
<p>So the more I'm likely to interrupt and take issue.</p>
<p>Speaker A 00:35:57</p>
<p>There's a lot of people who would be like, fuck the car and fuck the plane medicine.</p>
<p>Speaker A 00:36:02</p>
<p>We got you.</p>
<p>Speaker A 00:36:03</p>
<p>That sounds like that's the thing we want, but did you notice that cars have ravaged North America and turned it into a dystopian wasteland?</p>
<p>Speaker A 00:36:11</p>
<p>Granted that's a subjective emotional analysis, but in articulating that sentiment, consider it to be widespread amongst a growing part of the population.</p>
<p>Speaker A 00:36:23</p>
<p>Although I own a Ford F150, so I am not necessarily speaking for myself, but I want you to come back to genetics and policy because I think you did make a successful articulation of why too much regulation can hinder innovation.</p>
<p>Speaker A 00:36:40</p>
<p>Although I do think that that is contentious.</p>
<p>Speaker A 00:36:42</p>
<p>But are there other policies?</p>
<p>Speaker A 00:36:44</p>
<p>Because data and genetic data, for example, because we talked about data earlier, that tends to be a hot button issue for people, although I sometimes wonder if it's misplaced.</p>
<p>Speaker A 00:36:56</p>
<p>Do you have any thoughts on the regulations around genetic data and the sharing of it for research purposes, for example?</p>
<p>Speaker B 00:37:05</p>
<p>Of course.</p>
<p>Speaker B 00:37:05</p>
<p>So I'll attack this from two different prongs for you and you can stop me in the middle if you have any questions or inputs.</p>
<p>Speaker B 00:37:14</p>
<p>There's.</p>
<p>Speaker B 00:37:14</p>
<p>There's two factors to this.</p>
<p>Speaker B 00:37:16</p>
<p>One is government policy and regulation.</p>
<p>Speaker B 00:37:19</p>
<p>The other one is.</p>
<p>Speaker B 00:37:21</p>
<p>Actually, I have more put more importance on this one.</p>
<p>Speaker B 00:37:25</p>
<p>The scientific community has its own hierarchy, its own regulatory perspective.</p>
<p>Speaker B 00:37:31</p>
<p>And it's not one that a lot of people talk about.</p>
<p>Speaker B 00:37:32</p>
<p>But if you for.</p>
<p>Speaker B 00:37:35</p>
<p>I'm going to use an example there, there was somebody I'm sure you've been aware that somebody in China actually cloned.</p>
<p>Speaker B 00:37:42</p>
<p>I'm not picking on China, it's just where it happened.</p>
<p>Speaker A 00:37:43</p>
<p>Yeah, yeah, yeah.</p>
<p>Speaker B 00:37:44</p>
<p>Somebody actually cloned a child.</p>
<p>Speaker B 00:37:47</p>
<p>There was an outroar from the entire global scientific community.</p>
<p>Speaker B 00:37:52</p>
<p>This was not done correctly, it was not done adequately, it was not done ethically.</p>
<p>Speaker B 00:37:55</p>
<p>That individual was sidelined.</p>
<p>Speaker B 00:37:59</p>
<p>He could not access everything he needed to access.</p>
<p>Speaker B 00:38:02</p>
<p>He was blue balls, nobody would consider him.</p>
<p>Speaker B 00:38:05</p>
<p>He couldn't get win and obel.</p>
<p>Speaker B 00:38:07</p>
<p>So I think the scientific community has its own sense of morality and ethics where you have to do things the correct way, you have to do things in a.</p>
<p>Speaker A 00:38:18</p>
<p>That is a fantastic example to your credit.</p>
<p>Speaker A 00:38:22</p>
<p>I think this is something that very few people are aware of or reference difference.</p>
<p>Speaker A 00:38:26</p>
<p>But the peer to peer culture within the research community, especially something as contentious as genetic research is very powerful and does, does provide an alternate form of authority that can regulate and govern a research community.</p>
<p>Speaker A 00:38:45</p>
<p>But again because this is a game show and I'm trying to do as much comedy as possible.</p>
<p>Speaker A 00:38:49</p>
<p>Let me throw a counterexample at you, Jordan motherfucking Peterson.</p>
<p>Speaker A 00:38:55</p>
<p>Cuz here's a guy who is completely rejected by the scientific community that surrounds what he claims to be an expert in.</p>
<p>Speaker A 00:39:05</p>
<p>And I knew the guy before he was famous, you know, when he was actually at a time credible.</p>
<p>Speaker A 00:39:10</p>
<p>But he's very popular and becoming very rich as an entertainer.</p>
<p>Speaker A 00:39:15</p>
<p>But his authority as an entertainer is a direct translation, a trust transference of the perception that his peers respect him when they absolutely fucking do not.</p>
<p>Speaker B 00:39:29</p>
<p>Correct.</p>
<p>Speaker A 00:39:30</p>
<p>Are you able to explain this anomaly?</p>
<p>Speaker B 00:39:32</p>
<p>Yeah, Canada just tried to revoke his recently.</p>
<p>Speaker B 00:39:35</p>
<p>I don't think it was successful.</p>
<p>Speaker B 00:39:36</p>
<p>I need to fact check myself.</p>
<p>Speaker A 00:39:38</p>
<p>But I think it's still, still in process ending.</p>
<p>Speaker B 00:39:41</p>
<p>Yeah, they're trying to revoke his license.</p>
<p>Speaker B 00:39:44</p>
<p>So you are correct the entire.</p>
<p>Speaker B 00:39:46</p>
<p>I think this is an amazing analogy but I think it is a little bit nuanced, a little bit different.</p>
<p>Speaker B 00:39:53</p>
<p>Primarily because his colleagues have no respect for him.</p>
<p>Speaker B 00:39:59</p>
<p>Right.</p>
<p>Speaker B 00:39:59</p>
<p>From the psychological perspective.</p>
<p>Speaker B 00:40:02</p>
<p>So he's a clinical psychologist.</p>
<p>Speaker B 00:40:04</p>
<p>He's very intelligent, he's very well spoken.</p>
<p>Speaker B 00:40:07</p>
<p>Yeah, he has a tremendous following and he does it to monetize.</p>
<p>Speaker B 00:40:11</p>
<p>If that is his business is his business, it's not to better the world through his scientific.</p>
<p>Speaker A 00:40:17</p>
<p>So I agree.</p>
<p>Speaker A 00:40:18</p>
<p>But here's the problem.</p>
<p>Speaker A 00:40:19</p>
<p>YouTube and the other algorithmic taxonomy does not label him as entertainer like we label Joe Rogan as entertainer.</p>
<p>Speaker B 00:40:30</p>
<p>Sure.</p>
<p>Speaker A 00:40:30</p>
<p>Because we know he's an entertainer by the way.</p>
<p>Speaker A 00:40:32</p>
<p>Right.</p>
<p>Speaker A 00:40:33</p>
<p>But that's why he is who he is.</p>
<p>Speaker A 00:40:37</p>
<p>I prefer Howard Stern Myself, for the record.</p>
<p>Speaker B 00:40:40</p>
<p>Fair enough.</p>
<p>Speaker A 00:40:41</p>
<p>But Peterson is not labeled as an entertainer.</p>
<p>Speaker A 00:40:44</p>
<p>He's labeled in the same way that a genetic scientist is labeled, which is based on the authority of their peers.</p>
<p>Speaker A 00:40:52</p>
<p>And that's where I find you are correct to identify these alternate governance models.</p>
<p>Speaker A 00:40:58</p>
<p>But I guess this is my way of saying I don't trust them, even though they may be successful most of.</p>
<p>Speaker B 00:41:04</p>
<p>The time argument would be, when you lose that scientific.</p>
<p>Speaker B 00:41:08</p>
<p>When you lose the respect of your peers, right?</p>
<p>Speaker B 00:41:13</p>
<p>You may have a large following of the population, right?</p>
<p>Speaker B 00:41:17</p>
<p>You might be able to make a lot of money with it, but can you actually affect change and can you actually enforce policy?</p>
<p>Speaker B 00:41:22</p>
<p>Can you actually do anything?</p>
<p>Speaker B 00:41:23</p>
<p>Because nobody else is going to work with you, nobody's going to research with you.</p>
<p>Speaker B 00:41:26</p>
<p>My thought process is, congratulations, he's done a good job monetizing it because he's developed a massive following, but he is limited in what he can actually do aside from build his following and develop wealth.</p>
<p>Speaker A 00:41:40</p>
<p>So I wish you were true.</p>
<p>Speaker A 00:41:42</p>
<p>I wish what you said was true.</p>
<p>Speaker A 00:41:43</p>
<p>I would like to believe that's true.</p>
<p>Speaker A 00:41:46</p>
<p>But I do actually feel that on a regulatory level, he is having far more impact than the average psychologist whose ideas should be respected in the sense that I think the social sciences are witnessing a tragic delegitimization as part of a consequence of a larger ideological battle.</p>
<p>Speaker A 00:42:10</p>
<p>So congratulations, Stephen.</p>
<p>Speaker A 00:42:12</p>
<p>You have performed quite stellarly here on Metaviews.</p>
<p>Speaker A 00:42:17</p>
<p>Your answers have been very smart, insightful, beneficial, I think, to our audience.</p>
<p>Speaker A 00:42:24</p>
<p>So congratulations, you've made it to the boss level.</p>
<p>Speaker A 00:42:28</p>
<p>This is the final stage in the show before we go to the, you know, you've made it.</p>
<p>Speaker A 00:42:33</p>
<p>I hope you play video games or at least have some reference of video game culture.</p>
<p>Speaker A 00:42:39</p>
<p>This brings us to the politics stage.</p>
<p>Speaker B 00:42:42</p>
<p>Oh, fun.</p>
<p>Speaker A 00:42:43</p>
<p>Steven, where are we finding to please the fifth?</p>
<p>Speaker A 00:42:48</p>
<p>Of course.</p>
<p>Speaker A 00:42:48</p>
<p>Yeah.</p>
<p>Speaker A 00:42:49</p>
<p>Look, look, Steven, if.</p>
<p>Speaker A 00:42:51</p>
<p>If the subject is politics, you can answer like a politician, which is to dodge the fucking question entirely.</p>
<p>Speaker A 00:42:59</p>
<p>So let me start not specifically, but generally geographically.</p>
<p>Speaker A 00:43:03</p>
<p>Where are we reaching you today?</p>
<p>Speaker B 00:43:06</p>
<p>Sure.</p>
<p>Speaker B 00:43:06</p>
<p>So I'm a US citizen.</p>
<p>Speaker B 00:43:08</p>
<p>I'm based in Miami.</p>
<p>Speaker B 00:43:09</p>
<p>However, I do have an international presence.</p>
<p>Speaker B 00:43:12</p>
<p>I also have residency in a couple other European countries, as well as the Caribbean and Dubai.</p>
<p>Speaker A 00:43:22</p>
<p>The answer right now is Miami.</p>
<p>Speaker B 00:43:25</p>
<p>The answer right now is cold, freezing.</p>
<p>Speaker B 00:43:27</p>
<p>Canada.</p>
<p>Speaker A 00:43:28</p>
<p>Okay, where in Canada?</p>
<p>Speaker B 00:43:29</p>
<p>Toronto.</p>
<p>Speaker A 00:43:30</p>
<p>Okay, so you're in Toronto.</p>
<p>Speaker A 00:43:32</p>
<p>You know the last T is silent.</p>
<p>Speaker A 00:43:34</p>
<p>Right.</p>
<p>Speaker A 00:43:37</p>
<p>So I'm learning you've already disclosed that you are not a typical American, partly because you've left the country, but also because you do have a larger awareness that the world exists out of the country.</p>
<p>Speaker A 00:43:52</p>
<p>What is your take on the political situation in the United States?</p>
<p>Speaker A 00:43:56</p>
<p>And again, you don't have to divulge your ideological orientation unless you wish.</p>
<p>Speaker A 00:44:01</p>
<p>But I asked this question because I think most people, especially most literate, educated people, are experiencing a certain level of confusion.</p>
<p>Speaker A 00:44:11</p>
<p>And part of what we are trying to do here on Meta views is understand and understand understand the future.</p>
<p>Speaker A 00:44:17</p>
<p>You've clearly answered all the questions we've asked you so far with a tremendous amount of intellect and consideration.</p>
<p>Speaker A 00:44:24</p>
<p>So to the best of your ability, what do you what's your take on what's currently going on?</p>
<p>Speaker B 00:44:31</p>
<p>The fun thing is traveling while this is going on and getting other people's perspectives.</p>
<p>Speaker B 00:44:35</p>
<p>And it's so variable, country to country, because geopolitics is fascinating.</p>
<p>Speaker B 00:44:41</p>
<p>A lot of people don't spend the time to actually get asked the point of views of other people, how this is affecting them.</p>
<p>Speaker B 00:44:49</p>
<p>What is, what is this?</p>
<p>Speaker B 00:44:50</p>
<p>Are you angry at the tariffs?</p>
<p>Speaker B 00:44:52</p>
<p>Are you angry at this?</p>
<p>Speaker B 00:44:53</p>
<p>Or do you agree with what's happening right now?</p>
<p>Speaker B 00:44:56</p>
<p>So it's very interesting to get all these different perspectives to give you a sense of my take on it, my personal take.</p>
<p>Speaker B 00:45:05</p>
<p>I am, and I tell everyone I am politically and religiously agnostic and I love to have conversations that are unbiased, looking at both sides of the coin.</p>
<p>Speaker B 00:45:18</p>
<p>And I hate polarization.</p>
<p>Speaker B 00:45:19</p>
<p>I hate it so because the bias is.</p>
<p>Speaker A 00:45:23</p>
<p>Although as soon as you say, as soon as you say you hate polarization, you're no longer agnostic.</p>
<p>Speaker A 00:45:29</p>
<p>Right?</p>
<p>Speaker B 00:45:30</p>
<p>And I.</p>
<p>Speaker B 00:45:31</p>
<p>Agnostic is not choosing either side of the fence.</p>
<p>Speaker A 00:45:36</p>
<p>No, but you just chose the center and that is a choice and that makes you no longer.</p>
<p>Speaker B 00:45:42</p>
<p>But that in and of itself is.</p>
<p>Speaker B 00:45:44</p>
<p>The definition of agnostic is.</p>
<p>Speaker A 00:45:45</p>
<p>No, no, no, no, no.</p>
<p>Speaker A 00:45:47</p>
<p>Those are two different definitions.</p>
<p>Speaker A 00:45:48</p>
<p>Because if you were agnostic, you would also be indifferent to the center.</p>
<p>Speaker A 00:45:52</p>
<p>And again, I'm just a language nerd.</p>
<p>Speaker A 00:45:54</p>
<p>What your politics is, I don't mind.</p>
<p>Speaker B 00:45:57</p>
<p>I know this is, this is a good battle of words, but is not this center itself indifferent?</p>
<p>Speaker A 00:46:03</p>
<p>No, not in any way, shape or form.</p>
<p>Speaker A 00:46:06</p>
<p>And I say this to you, I say this to you as a Canadian where we have three parties, so we actually have a party that tries to represent the center.</p>
<p>Speaker A 00:46:15</p>
<p>Right versus the United States does not have that right.</p>
<p>Speaker A 00:46:18</p>
<p>You have the dichotomy of left versus right and therefore the center.</p>
<p>Speaker A 00:46:22</p>
<p>To your point, you can get away at calling it agnostic, but I'm just saying those are two different things.</p>
<p>Speaker A 00:46:28</p>
<p>So quick follow up question.</p>
<p>Speaker A 00:46:29</p>
<p>To your point of asking people when you travel, obviously, because you're in Toronto and you're talking to Canadians.</p>
<p>Speaker A 00:46:38</p>
<p>What have you.</p>
<p>Speaker A 00:46:39</p>
<p>What's your read of the current Canadian sentiment?</p>
<p>Speaker A 00:46:42</p>
<p>What's the views.</p>
<p>Speaker A 00:46:44</p>
<p>What views have been expressed to you?</p>
<p>Speaker B 00:46:48</p>
<p>Current sentiment is fuck you to the US and quite eloquent, I would, I would say.</p>
<p>Speaker B 00:46:58</p>
<p>And I'm sorry, you can bleed.</p>
<p>Speaker A 00:46:59</p>
<p>No, that was absolutely.</p>
<p>Speaker A 00:47:00</p>
<p>No, you got it fucking right again.</p>
<p>Speaker A 00:47:03</p>
<p>You're winning at the boss level.</p>
<p>Speaker A 00:47:04</p>
<p>Please continue.</p>
<p>Speaker B 00:47:05</p>
<p>Okay, good, good, good.</p>
<p>Speaker B 00:47:06</p>
<p>Just didn't know if it was one of those game shows.</p>
<p>Speaker B 00:47:09</p>
<p>So that is the over.</p>
<p>Speaker B 00:47:13</p>
<p>The overarchal sentiment that I am getting now.</p>
<p>Speaker B 00:47:16</p>
<p>It's not universal.</p>
<p>Speaker B 00:47:17</p>
<p>There are.</p>
<p>Speaker B 00:47:17</p>
<p>I've come across a couple that are actually in favor of what's going on.</p>
<p>Speaker B 00:47:21</p>
<p>They're very anti what's going on in the Canadian government.</p>
<p>Speaker B 00:47:23</p>
<p>And I've actually learned a lot about what's happening in the Canadian government that I didn't know prior to coming here.</p>
<p>Speaker B 00:47:28</p>
<p>But it's fascinating that I would say a good 80 to 90% of people currently are at odds with what's happening in the U.S.</p>
<p>Speaker B 00:47:36</p>
<p>they don't like the pressure.</p>
<p>Speaker B 00:47:37</p>
<p>They see the U.S.</p>
<p>Speaker B 00:47:38</p>
<p>as bullies, which I currently can't really combat.</p>
<p>Speaker B 00:47:43</p>
<p>They're just flexing their muscle at this point and trying to pressure everybody into kind of bending the knee or else I think it's going to.</p>
<p>Speaker B 00:47:51</p>
<p>We'll see what happens.</p>
<p>Speaker B 00:47:52</p>
<p>Obviously it's still very early, but yeah, the sentiment in Canada is not echoed everywhere we travel.</p>
<p>Speaker B 00:48:00</p>
<p>For example, when you go to the uae, it's flipped.</p>
<p>Speaker B 00:48:03</p>
<p>It's vice versa.</p>
<p>Speaker B 00:48:05</p>
<p>The vast majority of people, individuals that you speak with, whether they're business or workers, they're in favor of what's going on.</p>
<p>Speaker B 00:48:13</p>
<p>So it really depends on where you go.</p>
<p>Speaker B 00:48:14</p>
<p>When you go to the Caribbean, same thing.</p>
<p>Speaker B 00:48:16</p>
<p>Now granted, there's a lot of American citizens in the Caribbean, of course, so it really depends on where you go.</p>
<p>Speaker B 00:48:21</p>
<p>But currently I think it's very polarized.</p>
<p>Speaker B 00:48:24</p>
<p>You're either for or against for the vast majority of people.</p>
<p>Speaker B 00:48:26</p>
<p>It's very rare for me to ask somebody what their take is and get.</p>
<p>Speaker B 00:48:31</p>
<p>Eh.</p>
<p>Speaker A 00:48:32</p>
<p>See, I might argue that that's partly because you are traveling in centers of capital.</p>
<p>Speaker A 00:48:39</p>
<p>I live in eastern Ontario.</p>
<p>Speaker A 00:48:41</p>
<p>I spent most of my life in Toronto.</p>
<p>Speaker A 00:48:43</p>
<p>But here in eastern Ontario, there actually is quite a bit more support for Trump.</p>
<p>Speaker A 00:48:47</p>
<p>And where I think you're right at, like Toronto, it's like a 955 or a 90 10.</p>
<p>Speaker A 00:48:53</p>
<p>Where I'm at, it's maybe more of a 70, 30.</p>
<p>Speaker A 00:48:55</p>
<p>And given time, I think there's room for that 30 to grow.</p>
<p>Speaker A 00:48:59</p>
<p>And again it's just because eastern Ontario has a much different culture than Toronto.</p>
<p>Speaker A 00:49:05</p>
<p>But I regularly encounter people who I would argue are truly agnostic in the sense that they.</p>
<p>Speaker A 00:49:11</p>
<p>They have no fucks to give and they're just going about their lives kind of, you know, whatever, whatever, and they'd rather not hear about any of it from either side, which is a whole separate issue.</p>
<p>Speaker A 00:49:24</p>
<p>But I appreciated your accurate reading of the, you know, go fuck yourself sentiment amongst Canadians right now, because I've had a couple Americans on the show who, you know, were really smart about the stuff that they are able to talk about, but when I gave them debate on the hey, what's going on?</p>
<p>Speaker A 00:49:43</p>
<p>You know, they were like, oh, yeah, and our Canadian friends really like all this stuff.</p>
<p>Speaker A 00:49:46</p>
<p>I was like, oh, really?</p>
<p>Speaker B 00:49:49</p>
<p>You know, and you never know.</p>
<p>Speaker B 00:49:52</p>
<p>It's possible.</p>
<p>Speaker B 00:49:52</p>
<p>But I mean, I, I would.</p>
<p>Speaker B 00:49:54</p>
<p>I would tend to call BS on that, but obviously.</p>
<p>Speaker A 00:49:57</p>
<p>Oh, no, it was.</p>
<p>Speaker A 00:49:58</p>
<p>These were people who were just buying what the White House is selling and.</p>
<p>Speaker A 00:50:04</p>
<p>And, you know, and I don't do.</p>
<p>Speaker B 00:50:05</p>
<p>That regardless of who's in.</p>
<p>Speaker A 00:50:07</p>
<p>Yes, exactly.</p>
<p>Speaker B 00:50:09</p>
<p>Politics is politics, which is why I toe that middle line very, very tightly.</p>
<p>Speaker B 00:50:14</p>
<p>Although, again, I take it with a grain of salt.</p>
<p>Speaker A 00:50:17</p>
<p>I encourage you to spend time meditating on the difference between agnosticism and centrism, because I think you desire agnosticism fundamentally.</p>
<p>Speaker A 00:50:26</p>
<p>Right.</p>
<p>Speaker A 00:50:26</p>
<p>I think the nature of your kind of intellectual outlook is genuinely agnostic.</p>
<p>Speaker A 00:50:35</p>
<p>And I suspect in the months and years to come, you're going to find the centrists to be less and less desirable because I've planted the intellectual seed in your head that they are fundamentally not agnostics.</p>
<p>Speaker A 00:50:49</p>
<p>And you're going to start seeing that difference as time moves forward.</p>
<p>Speaker A 00:50:53</p>
<p>This is the subversive nature of language and reality hacking.</p>
<p>Speaker A 00:51:00</p>
<p>Congratulations.</p>
<p>Speaker A 00:51:02</p>
<p>You've made it to the last segment of every metaviews, which is the shout outs.</p>
<p>Speaker A 00:51:08</p>
<p>This is where we ask our guests to pay it forward.</p>
<p>Speaker A 00:51:11</p>
<p>If there is anyone really one that you would like to shout out, again, it's in the point of letting our audience know someone that they should be paying attention to, someone they should follow.</p>
<p>Speaker A 00:51:24</p>
<p>I jumped the gun earlier when I boosted Mikey Oppenheim and Coffin Talk, which is a podcast that gets into death, a subject that people don't like talking about.</p>
<p>Speaker A 00:51:35</p>
<p>And he's a pretty funny guy, so it's a pretty funny podcast.</p>
<p>Speaker A 00:51:39</p>
<p>Stephen, who would you like to shout out?</p>
<p>Speaker A 00:51:41</p>
<p>Living Dead, Real, Fictional.</p>
<p>Speaker A 00:51:43</p>
<p>But again, just one.</p>
<p>Speaker B 00:51:45</p>
<p>Oh, my goodness, there's so many people.</p>
<p>Speaker B 00:51:47</p>
<p>But since we were talking about genetics, I'm going to.</p>
<p>Speaker B 00:51:52</p>
<p>I'm going to call out Dr.</p>
<p>Speaker B 00:51:54</p>
<p>Davidson Claire out of Harvard Med.</p>
<p>Speaker B 00:51:57</p>
<p>Incredible, fascinating work that he's doing, actually.</p>
<p>Speaker B 00:51:59</p>
<p>That his anti aging genetic genetics that he's doing.</p>
<p>Speaker B 00:52:05</p>
<p>Incredible, fascinating stuff.</p>
<p>Speaker B 00:52:07</p>
<p>What he's been able to do with mice, what he's been able to do with primates.</p>
<p>Speaker B 00:52:10</p>
<p>It's, it's something that is definitely worth taking a look at.</p>
<p>Speaker B 00:52:14</p>
<p>Regardless of which side of the fence you happen to stand on genetic engineering and human longevity or immortality, it's fascinating stuff.</p>
<p>Speaker B 00:52:23</p>
<p>David Sinclair is doing incredible things over there.</p>
<p>Speaker A 00:52:27</p>
<p>I mean, ironically enough, here at Metaviews, we're part of the defense movement, which is that fences just get in the way of spontaneous conversations.</p>
<p>Speaker A 00:52:36</p>
<p>And I thank you, Stephen.</p>
<p>Speaker A 00:52:38</p>
<p>You have been a fantastic guest, really generous with your knowledge.</p>
<p>Speaker A 00:52:46</p>
<p>This has been another great episode of Meta Views.</p>
<p>Speaker A 00:52:49</p>
<p>We had a couple of shitty episodes, and not shitty in the sense of bad, just not so good in terms of audio quality.</p>
<p>Speaker A 00:52:58</p>
<p>So this was great having a smart guest with decent audio and perfectly willing to play the little silly games that we like to play here on Meta Views.</p>
<p>Speaker A 00:53:09</p>
<p>You can find us on YouTube, you can find us on Substack, you can find us on all the podcast platforms.</p>
<p>Speaker A 00:53:16</p>
<p>And our dogs willing, you can find us in the future.</p>
<p>Speaker A 00:53:21</p>
<p>So until then, please take care and we'll see you soon.</p>
<p>&quot;;}</p>

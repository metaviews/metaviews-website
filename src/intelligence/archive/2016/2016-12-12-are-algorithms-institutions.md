---
layout: layouts/intelligence-post.njk
title: 'Are Algorithms Institutions?'
date: 2016-12-12
description: 'Part three in an ongoing series'
tags:
  - 'Medium'
  - 'Analysis'
  - 'algorithms'
  - 'Institutions'
  - 'Part'
  - 'Three'
  - 'Ongoing'
medium_id: '5cfba851fb20'
---
<section name="e9a6" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><figure name="9884" id="9884" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*KZa6aqA9RCOXjcAYRxJeBA.jpeg" data-width="4032" data-height="3024" src="/assets/medium/2016-12-12-are-algorithms-institutions/1-KZa6aqA9RCOXjcAYRxJeBA-1715c473.jpeg"><figcaption class="imageCaption">Brooklyn Museum. Photo by Jesse Hirsh</figcaption></figure><p name="36ee" id="36ee" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Part three in an ongoing series</em></strong></p><p name="b193" id="b193" class="graf graf--p graf-after--p">To many, algorithms remain a mystery, a kind of hidden force that shapes the information they see on Facebook, or the results they get on Twitter (<a href="http://dl.acm.org/citation.cfm?id=2578883" data-href="http://dl.acm.org/citation.cfm?id=2578883" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Hamilton et al, 2014</a>). Many people are unaware that algorithms play any part in the information they receive: the better the algorithm, the less visible it is. Algorithms also play a hidden role when it comes to sorting the information that is used to judge and understand us, whether in the form of credit scores or insurance rates (<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376209" data-href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376209" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Citron et al, 2014</a>). Even for those who are able to use and access algorithms explicitly, that doesn’t mean they understand how they work, and thus may appear magical when it comes to the results or information that algorithms produce (<a href="http://nms.sagepub.com/content/early/2012/04/04/1461444812440159.abstract" data-href="http://nms.sagepub.com/content/early/2012/04/04/1461444812440159.abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Bucher, 2016</a>).</p><p name="de8c" id="de8c" class="graf graf--p graf-after--p">Unfortunately, if we assume that algorithms are invisible and capable of magic, then there is certainly no way we might understand them, let alone hold them democratically accountable.</p><p name="d3b9" id="d3b9" class="graf graf--p graf-after--p"><a href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" data-href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Philip Napoli (2014)</a> argues that institutional theory is a helpful analytical framework by which to examine and study the growing role of algorithms. Institutional theory looks at how rules, structures, and systems shape behaviour, and establish social norms. Napoli argues that algorithms are themselves institutional by nature (341) due to the evolving roles and functions that they serve in the dynamics of contemporary media systems, as well as their role in a growing number of other sectors.</p><p name="f993" id="f993" class="graf graf--p graf-after--p">To help establish this, Napoli delves into institutional theory, and the various kinds of institutions, both formal, and informal. Specifically Napoli cites the work of Ronald Jepperson who defines institutions as also including informal routines, norms, rules or behavioural guidelines.</p><p name="ed7c" id="ed7c" class="graf graf--p graf-after--p">It is a mistake to think of institutions as being exclusively formal, or even material. Rather, an institution can be as informal, or immaterial as any other social structure we see emerging in the internet era.</p><p name="3ae3" id="3ae3" class="graf graf--p graf-after--p">For example, <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2392711" data-href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2392711" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Christian Katzenbach (2012)</a> argues that algorithms are institutions because of the way in which they constrain and facilitate how we receive, share, and consume media. On Facebook we don’t see everything that our friends post, but rather that which the Facebook newsfeed algorithm has selected for us. Katzenbach goes even further to argue that technologies have embedded political ideologies, that reflect how they’ve been designed and deployed. The Facebook algorithm has a bias, that reflects the beliefs of the Facebook engineers and designers who created it.</p><p name="992c" id="992c" class="graf graf--p graf-after--p">In this respect, algorithms are themselves institutions, serve institutions, and create institutions, in the form of the audience configurations, networks, and relationships that they create. If the “medium is the message” (<a href="https://en.wikipedia.org/wiki/Understanding_Media" data-href="https://en.wikipedia.org/wiki/Understanding_Media" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">McLuhan, 1994</a>) than algorithms are both the path and the vehicle by which we engage with media. They produce both the content and the form by which we find and consume information.</p><h3 name="7410" id="7410" class="graf graf--h3 graf-after--p">A Response to or the Cause of Information Overload</h3><p name="d773" id="d773" class="graf graf--p graf-after--h3">Perhaps we take for granted the way in which the web and social media has created an information explosion, where there is far too much data for our brains to process, we have become reliant upon algorithms to sort through, categorize, and prioritize which information we will actually see and maybe read.</p><p name="dd33" id="dd33" class="graf graf--p graf-after--p"><a href="http://www.nickdiakopoulos.com/projects/algorithmic-accountability-reporting/" data-href="http://www.nickdiakopoulos.com/projects/algorithmic-accountability-reporting/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Nicholas Diakopoulos (2015)</a> identifies this algorithmic power as embodied in the decisions we ask them to make with regard to prioritization, classification, association, and filtering.</p><p name="1a87" id="1a87" class="graf graf--p graf-after--p">Similarly, <a href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" data-href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Philip Napoli (2014)</a> notes that: “one of the key functions that algorithms perform in contemporary media consumption is to assist audiences in the process of navigating an increasingly complex and fragmented media environment.” (345)</p><p name="fd38" id="fd38" class="graf graf--p graf-after--p">This process of navigation results in a kind of institutional relationship. <a href="http://mkhufs.pbworks.com/w/file/fetch/79356995/Webster_UserInfoRegimes_Bias_2010.pdf" data-href="http://mkhufs.pbworks.com/w/file/fetch/79356995/Webster_UserInfoRegimes_Bias_2010.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">James Webster (2010)</a> describes this in the way social media structures our consumption of media. He describes user information regimes as well as the co-operation that takes place between individuals and institutions with regard to what is consumed and what is not, i.e. what gets attention (<a href="http://webster.soc.northwestern.edu/pubs/Webster%20%282011%29%20Duality%20of%20Media.pdf" data-href="http://webster.soc.northwestern.edu/pubs/Webster%20(2011)%20Duality%20of%20Media.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Webster, 2011</a>).</p><p name="0afd" id="0afd" class="graf graf--p graf-after--p">For example, trending topics rise in visibility because people are talking about them. And yet once a topic becomes trending, it garners even more attention because of the fact it is trending. This resembles a kind of feedback loop where users and algorithms dance together creating a structure by which attention is directed. The concept of virality is more about catching and spreading the bug then it is the value of the bug itself. We don’t share something with one person, but with everyone. We also do not necessarily share something because we like it, but often because it is easy to share and will evoke a desired response from our network.</p><p name="3923" id="3923" class="graf graf--p graf-after--p">Even journalists need to consume information as part of their process of production, and face similar challenges when it comes to the volume and complexity of information, and thus also turn to algorithms as tools to help in their analysis and reporting (<a href="http://www.academia.edu/21821949/Artificial_Intelligence_for_Investigative_Reporting" data-href="http://www.academia.edu/21821949/Artificial_Intelligence_for_Investigative_Reporting" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Broussard, 2014</a>). However again, this relationship becomes a structure unto itself as those same journalists abandon non-algorithmic modes of discovery in favour of faster and perceivably more convenient sourcing via algorithm.</p><p name="0ec1" id="0ec1" class="graf graf--p graf-after--p">The problem in such a situation is not knowing what is not there. While we may see algorithms as a response to information overload, they are also the cause. They reinforce their authority and institutional power as we use them, while increasing the volume of information we consume, increasing our dependence on their ability to sort, filter, and prioritize the information we consume.</p><h3 name="2cb0" id="2cb0" class="graf graf--h3 graf-after--p">Algorithms That Socialize and Normalize Behaviour</h3><p name="0392" id="0392" class="graf graf--p graf-after--h3">Taina Bucher (2012) looks at algorithmic power and the threat of invisibility on Facebook. The way the news feed creates a culture of attention that encourages users to conform to the logic of the algorithm in order to achieve the likes and attention offered by their friends, should their friends end up seeing the post. A situation that rests on algorithmic filtering.</p><p name="24f3" id="24f3" class="graf graf--p graf-after--p">Social media users have a range of incentives to post and participate on these platforms, the largest being the desire to get attention from our friends and social contacts. The algorithms have a specific logic that either facilitates or rewards this attention, and this logic directly influences what we post and how we interact (<a href="http://www.tandfonline.com/doi/abs/10.1080/1369118X.2016.1154086" data-href="http://www.tandfonline.com/doi/abs/10.1080/1369118X.2016.1154086" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Bucher, 2016</a>).</p><p name="9c2d" id="9c2d" class="graf graf--p graf-after--p">Algorithms are also employed as enforcement mechanisms, providing a first line of defense against abusive language and behaviour that sites have deemed inappropriate (<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2741513" data-href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2741513" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Filmar et al, 2016</a>). They literally possess and employ the power to disappear offensive content and users.</p><p name="fe7d" id="fe7d" class="graf graf--p graf-after--p">This interaction between individuals and institutions, as facilitated by the algorithm, creates an emerging institutional structure.</p><p name="ee8e" id="ee8e" class="graf graf--p graf-after--p">The example of Netflix’s recommendation engine is given, as something users rely upon to find content, and yet the engine depends upon users input to achieve accurate recommendations (<a href="https://books.google.ca/books/about/Netflixed.html?id=sodDcL2yhsIC&amp;redir_esc=y" data-href="https://books.google.ca/books/about/Netflixed.html?id=sodDcL2yhsIC&amp;redir_esc=y" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Keating, 2012</a>). The interface to browse through what Netflix makes available is deliberately opaque, whereas the recommendation engine is prominent and dominates the content discovery process. When it works we love it, when it fails, and recommends something we don’t like, we take notice, and wonder what went wrong.</p><p name="7763" id="7763" class="graf graf--p graf-after--p">Philip Napoli (<a href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" data-href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">2014</a>) notes that “two of the primary functions that algorithms are performing in the media production realm at this point are: (a) serving as a demand predictor and (b) serving as content creator.” (348)</p><p name="1988" id="1988" class="graf graf--p graf-after--p">The demand predictor element of algorithmic production is well documented by <a href="http://sloanreview.mit.edu/article/what-people-want-and-how-to-predict-it/" data-href="http://sloanreview.mit.edu/article/what-people-want-and-how-to-predict-it/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Thomas Davenport and Jeanne Harris in their work around what people want and how to predict it (2009)</a>. As more data becomes available, media companies face increasing pressure to rely upon algorithms to help them understand the preferences and desires of their audience. Certainly those who do not shift their production model so as to incorporate data driven decision making are left at a disadvantage compared to those who do. For example Netflix has a huge advantage compared to other media companies given their significant ability to collect data about the content they produce and distribute.</p><p name="52af" id="52af" class="graf graf--p graf-after--p">Napoli (<a href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" data-href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">2014</a>) argues that this is an example of “the institutionality of algorithms in that they facilitate and constrain the behaviors and cognitions of both media organizations and media users.” (353)</p><p name="03c0" id="03c0" class="graf graf--p graf-after--p">Napoli’s approach to institutional theory builds upon his earlier work on audience evolution with regard to new technologies (<a href="https://cup.columbia.edu/book/audience-evolution/9780231150347" data-href="https://cup.columbia.edu/book/audience-evolution/9780231150347" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">2011</a>) and together uses these perspectives to provide a lens for looking at how the industry is changing and how media audiences are changing along with it.</p><p name="22b3" id="22b3" class="graf graf--p graf-after--p">Perhaps this is best embodied by the way in which the practice of journalism is being impacted by this institutionality of algorithms (<a href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" data-href="http://onlinelibrary.wiley.com/doi/10.1111/comt.12039/abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Napoli, 2014</a>). Specifically, the algorithmic conception of the audience is changing the way in which journalists produce content, and how that content is received (<a href="http://ijoc.org/index.php/ijoc/article/view/884" data-href="http://ijoc.org/index.php/ijoc/article/view/884" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Anderson, 2011</a>).</p><p name="67a5" id="67a5" class="graf graf--p graf-after--p">Rather than chase stories based on their merit, trending topics and popularity as measured by algorithms influence what content news companies will produce. The audience is no longer a silent entity, but rather those who tweet and comment have a growing influence as they get the attention of journalists and producers and have an undue influence on what is then deemed important and produced.</p><p name="fff1" id="fff1" class="graf graf--p graf-after--p">It’s not just professional journalists who are being shaped and driven by algorithmic media but all journalists, paid or not, citizen journalists included (<a href="http://nms.sagepub.com/content/11/8/1287.abstract" data-href="http://nms.sagepub.com/content/11/8/1287.abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Goode, 2009</a>). Not to mention the rise of algorithmic journalism, articles written by software rather than humans, though they are still relatively few in number (<a href="http://www.tandfonline.com/doi/abs/10.1080/21670811.2015.1096748?journalCode=rdij20" data-href="http://www.tandfonline.com/doi/abs/10.1080/21670811.2015.1096748?journalCode=rdij20" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Dorr, 2015</a>). However, we should anticipate their growing influence and output by creating a sociology of algorithmic journalism to evaluate their work and impact (<a href="http://nms.sagepub.com/content/early/2012/12/06/1461444812465137.abstract" data-href="http://nms.sagepub.com/content/early/2012/12/06/1461444812465137.abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Anderson, 2013</a>).</p><p name="d858" id="d858" class="graf graf--p graf-after--p">It should also be noted that there is also room in this context to look at how algorithms impact other work, explicitly the management of workers. While Uber is certainly considered a “big data” company (<a href="http://www.forbes.com/sites/ronhirson/2015/03/23/uber-the-big-data-company/#200798e225f4" data-href="http://www.forbes.com/sites/ronhirson/2015/03/23/uber-the-big-data-company/#200798e225f4" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Hirson, 2015</a>), the drivers interface with the company via an app, and the algorithm behind that app has considerable control over what they do, how, and when (<a href="https://www.cs.cmu.edu/~mklee/materials/Publication/2015-CHI_algorithmic_management.pdf" data-href="https://www.cs.cmu.edu/~mklee/materials/Publication/2015-CHI_algorithmic_management.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Lee et al, 2015</a>).</p><p name="6721" id="6721" class="graf graf--p graf-after--p">Of course, in the era of social media, users themselves are workers, as they provide the content and labour that drives the use of social media sites (<a href="http://dl.acm.org/citation.cfm?id=1805123" data-href="http://dl.acm.org/citation.cfm?id=1805123" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Fuchs, 2010</a>). The by-product of this unpaid labour is the personal information and data derived from users, which is the primary commodity that companies sell to advertisers and data brokers, comprising the bulk of their revenue and profits (<a href="http://triple-c.at/index.php/tripleC/article/viewArticle/255" data-href="http://triple-c.at/index.php/tripleC/article/viewArticle/255" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Kang et al, 2011</a>). The convenience and ease of using these sites, thanks in large part due to algorithms, are largely what distract users from understanding the value they provide, or their status as workers.</p><h3 name="d724" id="d724" class="graf graf--h3 graf-after--p">Reality shaped by Algorithms</h3><p name="3fd5" id="3fd5" class="graf graf--p graf-after--h3">Media have traditionally shaped our perception of reality, and now that algorithms have become so pervasive, so far reaching, algorithms now play a growing role in the construction of our reality (<a href="http://www.emeraldinsight.com/doi/full/10.1108/info-05-2015-0025" data-href="http://www.emeraldinsight.com/doi/full/10.1108/info-05-2015-0025" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Saurwein, 2015</a>). Their influence is to increase individualization, commercialization, inequalities, and deterritorialization, while also decreasing transparency, controllability, and predictability (<a href="http://mcs.sagepub.com/content/early/2016/04/20/0163443716643157.abstract" data-href="http://mcs.sagepub.com/content/early/2016/04/20/0163443716643157.abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Just et al, 2016</a>).</p><p name="5260" id="5260" class="graf graf--p graf-after--p">The individualization comes in the form of customized and subjective interfaces created by algorithmically sorted newsfeeds and search results. The commercialization reflects the logic of the companies operating those algorithms, in that they are all driven by advertising, and the perpetual need to sell us more stuff. The inequalities reflect the inherent hierarchy of algorithmic media, in that they rank and sort users based on engagement, activity, and influence, The deterritorialization reflects the often agnostic approach to where a user is located, in spite of the personalization of location, as real time media is more about global reach than it is local relevance. The decreased transparency is a consequence of algorithmic opaqueness, which is also reflected in the decreased control, and therefore decreased predictability.</p><p name="90d6" id="90d6" class="graf graf--p graf-after--p">Therefore, the algorithm as institution also impacts other institutions, and in particular we should be concerned about those charged with governing or managing democracy.</p><p name="f10a" id="f10a" class="graf graf--p graf-after--p">For example, Robert Epstein and Ronald Robertson have been conducting research around the concept of the Search Engine Manipulation Effect (SEME) and the way in which biased search engine results can dramatically alter the outcome of an election (<a href="http://www.pnas.org/content/112/33/E4512.abstract" data-href="http://www.pnas.org/content/112/33/E4512.abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Epstein et al, 2015</a>). As more and more voters turn to social media and search engines as a means of becoming informed about issues and candidates, the more they depend upon algorithms, and the greater the opportunity for those algorithms to impact their views, and thus the outcome of electoral contests.</p><p name="496d" id="496d" class="graf graf--p graf-after--p">A similar and rather chilling example of SEME is being piloted by Google in the UK as a measure to combat extremist ideology and terrorist activities. The company revealed to the British Parliament the ability to identify an extremist or terrorist based on their search patterns, at which point the search engine would replace the content the subject was seeking with information that sought to convince them to stop being a terrorist (<a href="http://www.telegraph.co.uk/technology/google/12136765/Google-to-deliver-wrong-search-results-to-would-be-jihadis.html" data-href="http://www.telegraph.co.uk/technology/google/12136765/Google-to-deliver-wrong-search-results-to-would-be-jihadis.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Barrett, 2016</a>). All done without the subject’s knowledge or consent. If this kind of manipulation becomes acceptable when dealing with some elements of society what is to stop the technique from being used on others?</p><p name="ff8e" id="ff8e" class="graf graf--p graf-after--p">In another context, there is growing interest in the rise of high frequency trading and the role of algorithms in capital markets. While proponents argue the technology allows for these markets to operate as efficiently and rapidly as possible, critics point to how these algorithms can and are being used to manipulate other market participants (<a href="http://tcs.sagepub.com/content/early/2015/02/26/0263276414566642" data-href="http://tcs.sagepub.com/content/early/2015/02/26/0263276414566642" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Arnoldi, 2016</a>). Should we embrace the notion of “buyer beware” (even if the buyer is blind to the manipulation) or should there be greater controls to ensure capital markets are fair and transparent?</p><p name="7311" id="7311" class="graf graf--p graf-after--p">What about the new and emerging phenomena of hack or flash crashes that result when algorithms react to erroneous information and cause rapid volatility in capital markets? One known instance of this was when the Associated Press Twitter account was hacked, and a fraudulent tweet caused $136.5 billion to be wiped out of the S&amp;P 500 index within seconds (<a href="http://tcs.sagepub.com/content/early/2015/05/04/0263276415583139.abstract" data-href="http://tcs.sagepub.com/content/early/2015/05/04/0263276415583139.abstract" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Karppi et al, 2016</a>). While this is not the only flash crash that has occurred, it is one of the only instances where we can understand the cause and effect. How many more will occur before regulators recognize the power that algorithms possess?</p><p name="489b" id="489b" class="graf graf--p graf-after--p">When using the lens of institutional theory, we can begin to get a sense of the power of algorithms, and the growing institutional role they are playing in our society. This suggests that algorithms require an institutional response, if not a kind of regulation that powerful institutions are subject to. What form that takes place will be a significant political issue for us to address. Not doing so invites catastrophe. We ignore the rapid rise of powerful institutions at our peril.</p><p name="480b" id="480b" class="graf graf--p graf-after--p">However, regarding algorithms as institutions, specifically as media institutions, suggests we also look at the relationship between algorithms and audiences, in particular audience research.</p><p name="0812" id="0812" class="graf graf--p graf-after--p graf--trailing"><a href="https://roughdraft.review/are-algorithms-enabling-autonomous-audiences-7464e5bda663" data-href="https://roughdraft.review/are-algorithms-enabling-autonomous-audiences-7464e5bda663" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Continued in Part 4</em></strong></a></p></div></div></section>
